{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/Users/roopal/workspace/kaggle/quora_question_pairs/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = os.path.join(data_dir, \"train.csv\")\n",
    "test_file = os.path.join(data_dir, \"test.csv\")\n",
    "sample_submission = os.path.join(data_dir, \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_file, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPO_LOCAL_PATH = \"/Users/roopal/ggrepo/ds-tws-backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo local path added\n"
     ]
    }
   ],
   "source": [
    "if REPO_LOCAL_PATH not in sys.path:\n",
    "    sys.path.append(REPO_LOCAL_PATH)\n",
    "    print \"repo local path added\"\n",
    "else:\n",
    "    print \"repo local path already added\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util.util_text_process import get_sentence_tokenizer, get_sentences, tokenize as tokenize_en\n",
    "from deep_learning.embeddings.Word2VecEmbeddings import Word2VecEmbeddings\n",
    "from deep_learning.corpus_reader.CorpusReader import CorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75517\n",
      "126790\n",
      "93153\n",
      "128059\n",
      "33072\n",
      "123344\n",
      "110474\n",
      "106841\n",
      "109880\n",
      "77163\n",
      "99722\n",
      "121716\n",
      "71599\n",
      "100680\n",
      "73005\n",
      "105561\n",
      "73425\n",
      "100906\n",
      "25057\n",
      "115515\n",
      "116461\n",
      "114756\n",
      "61857\n",
      "46360\n",
      "115287\n",
      "123233\n",
      "53784\n",
      "126835\n",
      "122720\n",
      "74398\n",
      "79246\n",
      "31419\n",
      "122737\n",
      "31628\n",
      "27050\n",
      "113791\n",
      "104262\n",
      "101729\n",
      "95669\n",
      "99079\n",
      "96218\n",
      "125787\n",
      "102513\n",
      "43731\n",
      "97887\n",
      "85086\n",
      "59179\n",
      "117986\n"
     ]
    }
   ],
   "source": [
    "wrd2idx, _ = Word2VecEmbeddings.get_embeddings_with_custom_tokens(\n",
    "    '/Users/roopal/workspace/kaggle/quora_question_pairs/data/w2v.model.bin', binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD2IDX = wrd2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EN_SENT_TOKENIZER = get_sentence_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_sentences(sentences, word2idx, build_word2idx=False):\n",
    "    list_line_word_idx = list()\n",
    "    for sentence in sentences:\n",
    "        sentence = CorpusReader.clean_line(sentence)\n",
    "        \n",
    "        words = tokenize_en(sentence)\n",
    "        \n",
    "        line_word_idx = list()\n",
    "        for word in words:\n",
    "            idx = CorpusReader.get_word_index(word, word2idx, build_word2idx)\n",
    "            line_word_idx.append(idx)\n",
    "        list_line_word_idx.append(line_word_idx)\n",
    "        \n",
    "    return list_line_word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_question_sent_idx(question1):\n",
    "    try:\n",
    "        q1 = process_sentences([question1], WORD2IDX)\n",
    "    except Exception as e:\n",
    "        print str(e), question1\n",
    "        q1 = [[]]\n",
    "        \n",
    "#     try:\n",
    "#         q2 = process_sentences([question2], WORD2IDX)\n",
    "#     except Exception as e:\n",
    "#         print str(e), question2\n",
    "#         q2 = []\n",
    "#     return id, q1, q2\n",
    "    return q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train[\"q1_sent_idx\"] = df_train[\"question1\"].apply(lambda x: get_question_sent_idx(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train[\"q2_sent_idx\"] = df_train[\"question2\"].apply(lambda x: get_question_sent_idx(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>q1_sent_idx</th>\n",
       "      <th>q2_sent_idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_duplicate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255025</td>\n",
       "      <td>255025</td>\n",
       "      <td>255025</td>\n",
       "      <td>255025</td>\n",
       "      <td>255025</td>\n",
       "      <td>255025</td>\n",
       "      <td>255025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149263</td>\n",
       "      <td>149263</td>\n",
       "      <td>149263</td>\n",
       "      <td>149263</td>\n",
       "      <td>149263</td>\n",
       "      <td>149263</td>\n",
       "      <td>149263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id    qid1    qid2 question1 question2 q1_sent_idx  \\\n",
       "               count   count   count     count     count       count   \n",
       "is_duplicate                                                           \n",
       "0             255025  255025  255025    255025    255025      255025   \n",
       "1             149263  149263  149263    149263    149263      149263   \n",
       "\n",
       "             q2_sent_idx  \n",
       "                   count  \n",
       "is_duplicate              \n",
       "0                 255025  \n",
       "1                 149263  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby([\"is_duplicate\"]).agg([\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_pickle(train_file+\".q_w2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_file, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected string or buffer nan\n",
      "expected string or buffer nan\n"
     ]
    }
   ],
   "source": [
    "df_test[\"q1_sent_idx\"] = df_test[\"question1\"].apply(lambda x: get_question_sent_idx(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected string or buffer nan\n",
      "expected string or buffer nan\n",
      "expected string or buffer nan\n",
      "expected string or buffer nan\n"
     ]
    }
   ],
   "source": [
    "df_test[\"q2_sent_idx\"] = df_test[\"question2\"].apply(lambda x: get_question_sent_idx(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_pickle(test_file+\".q_w2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94646 [[]]\n",
      "714289 [[]]\n",
      "805015 [[]]\n",
      "913286 [[]]\n",
      "923320 [[]]\n",
      "1046690 [[]]\n",
      "1221596 [[]]\n",
      "1461432 [[]]\n"
     ]
    }
   ],
   "source": [
    "for item, frame in df_test[\"q1_sent_idx\"].iteritems():\n",
    "    if len(frame) == 1 and len(frame[0]) > 0:\n",
    "        continue\n",
    "    print item, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379205 [[]]\n",
      "788917 [[]]\n",
      "817520 [[]]\n",
      "856433 [[]]\n",
      "943911 [[]]\n",
      "963864 [[]]\n",
      "1250219 [[]]\n",
      "1270024 [[]]\n",
      "1635393 [[]]\n",
      "2164990 [[]]\n"
     ]
    }
   ],
   "source": [
    "for item, frame in df_test[\"q2_sent_idx\"].iteritems():\n",
    "    if len(frame) == 1 and len(frame[0]) > 0:\n",
    "        continue\n",
    "    print item, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done...\n"
     ]
    }
   ],
   "source": [
    "print \"done...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
